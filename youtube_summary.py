import os, json, random ,asyncio, re
from tqdm import tqdm
import gspread
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from datetime import datetime, timedelta
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api.proxies import WebshareProxyConfig
import openai
from dotenv import load_dotenv
# conda activate recent
# cd /c/Users/ENVY/Desktop/youtube/hy-navercafe-cralwer
load_dotenv()

# ==========================================
# 1. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
# ==========================================
YOUTUBE_API_KEY = os.environ.get("GCP_API_KEY") 
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
GCP_SA_KEY_STR = os.environ.get("GCP_SA_KEY") 
PROXY_USERNAME = os.environ.get("PROXY_USERNAME")
PROXY_PASSWORD = os.environ.get("PROXY_PASSWORD")

TARGET_SPREADSHEET_URL = "https://docs.google.com/spreadsheets/d/1vXco0waE_iBVhmXUqMe7O56KKSjY6bn4MiC3btoAPS8/edit"
SOURCE_SHEET_NAME = "ìœ íŠœë¸Œì •ë¦¬"
TARGET_SHEET_NAME = "ìœ íŠœë¸Œ ìš”ì•½"

# dynamic_start_date = (datetime.now() - timedelta(days=5)).strftime('%Y-%m-%d')
# START_DATE = dynamic_start_date
START_DATE = "2024-01-01" 
TEST_NUM = None # Noneìœ¼ë¡œ í•˜ë©´ ì „ì²´ ìˆ˜ì§‘

SHEET_CELL_LIMIT = 45000 
GPT_INPUT_LIMIT = 100000 
CONCURRENT_LIMIT = 15 
semaphore = asyncio.Semaphore(CONCURRENT_LIMIT)

aclient = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)

# ==========================================
# [ê³µí†µ] ì¬ì‹œë„ ë¡œì§
# ==========================================
async def retry_action(func, *args, retries=3, delay=60, description="ì‘ì—…"):
    for attempt in range(retries):
        try:
            if asyncio.iscoroutinefunction(func):
                return await func(*args)
            else:
                loop = asyncio.get_running_loop()
                return await loop.run_in_executor(None, func, *args)
        except Exception as e:
            if attempt == retries - 1:
                return None
            await asyncio.sleep(delay)
    return None

# ==========================================
# 2. êµ¬ê¸€ ì‹œíŠ¸ & ë§í¬ ì¶”ì¶œ
# ==========================================
def connect_google_sheet(sheet_name=None):
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    if GCP_SA_KEY_STR:
        creds = Credentials.from_service_account_info(json.loads(GCP_SA_KEY_STR), scopes=scopes)
    else:
        creds = Credentials.from_service_account_file("service_account.json", scopes=scopes)
    
    client = gspread.authorize(creds)
    spreadsheet = client.open_by_url(TARGET_SPREADSHEET_URL)
    
    if sheet_name:
        try:
            sheet = spreadsheet.worksheet(sheet_name)
        except gspread.exceptions.WorksheetNotFound:
            if sheet_name == TARGET_SHEET_NAME:
                sheet = spreadsheet.add_worksheet(title=TARGET_SHEET_NAME, rows=100, cols=20)
                sheet.append_row(["ì±„ë„ëª…", "ë‚ ì§œ", "ì œëª©", "ìŠ¤í¬ë¦½íŠ¸", "GPTìš”ì•½", "URL"])
            else:
                raise Exception(f"âŒ '{sheet_name}' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return sheet
    return spreadsheet

def extract_links_using_api(spreadsheet_url, sheet_name):
    try:
        spreadsheet_id = spreadsheet_url.split("/d/")[1].split("/")[0]
        scopes = ["https://www.googleapis.com/auth/spreadsheets"]
        if GCP_SA_KEY_STR:
            creds = Credentials.from_service_account_info(json.loads(GCP_SA_KEY_STR), scopes=scopes)
        else:
            creds = Credentials.from_service_account_file("service_account.json", scopes=scopes)
        service = build('sheets', 'v4', credentials=creds)

        range_name = f"{sheet_name}!C2:C"
        print(f"ğŸ“¡ êµ¬ê¸€ ì‹œíŠ¸ API ìš”ì²­ ì¤‘... ({range_name})")
        fields_param = "sheets(data(rowData(values(hyperlink,userEnteredValue,formattedValue))))"
        result = service.spreadsheets().get(spreadsheetId=spreadsheet_id, ranges=[range_name], fields=fields_param).execute()

        extracted_data = []
        if 'sheets' in result and 'data' in result['sheets'][0]:
            rows = result['sheets'][0]['data'][0].get('rowData', [])
            for row in rows:
                if not row.get('values'):
                    extracted_data.append(None); continue
                cell_data = row['values'][0]
                url = None
                if 'hyperlink' in cell_data: url = cell_data['hyperlink']
                elif 'userEnteredValue' in cell_data and 'formulaValue' in cell_data['userEnteredValue']:
                    match = re.search(r'"(https?://.*?)"', cell_data['userEnteredValue']['formulaValue'])
                    if match: url = match.group(1)
                elif 'formattedValue' in cell_data and str(cell_data['formattedValue']).startswith("http"):
                    url = cell_data['formattedValue']
                extracted_data.append(url)
        return extracted_data
    except Exception as e:
        print(f"âŒ ì‹œíŠ¸ API ì—ëŸ¬: {e}"); return []

def get_channel_id_from_url(youtube, url):
    if not url or "youtube.com" not in url: return None
    try:
        if "@" in url:
            handle = url.split("@")[-1].split("/")[0].split("?")[0]
            res = youtube.channels().list(part="id", forHandle=f"@{handle}").execute()
            if res.get("items"): return res["items"][0]["id"]
        if "/channel/" in url:
            return url.split("/channel/")[-1].split("/")[0].split("?")[0]
    except: return None
    return None

def fetch_channel_ids_from_sheet():
    urls = extract_links_using_api(TARGET_SPREADSHEET_URL, SOURCE_SHEET_NAME)
    if not urls: return []
    youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
    channel_ids = []
    for url in urls:
        if not url: continue
        ch_id = get_channel_id_from_url(youtube, url)
        if ch_id: channel_ids.append(ch_id)
    unique_ids = list(set(channel_ids))
    print(f"âœ… ìµœì¢… ì‹ë³„ëœ ì±„ë„ ID: {len(unique_ids)}ê°œ")
    return unique_ids

# ==========================================
# 4. ì˜ìƒ ëª©ë¡ ìˆ˜ì§‘ (ì‡¼ì¸  ì œì™¸)
# ==========================================
def get_all_videos(channel_id, start_date):
    try:
        youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
        res = youtube.channels().list(id=channel_id, part="snippet,contentDetails").execute()
        if not res["items"]: return [], "Unknown"
        channel_title = res["items"][0]["snippet"]["title"]
        
        # [UULF ì ìš©] ì‡¼ì¸  ì œì™¸
        real_channel_id = res["items"][0]["id"]
        playlist_id = real_channel_id.replace("UC", "UULF", 1)
        
        videos = []
        next_page_token = None
        stop_collecting = False
        while not stop_collecting:
            try:
                pl_res = youtube.playlistItems().list(playlistId=playlist_id, part="snippet", maxResults=50, pageToken=next_page_token).execute()
                for item in pl_res["items"]:
                    video_id = item["snippet"]["resourceId"]["videoId"]
                    title = item["snippet"]["title"]
                    published_at = item["snippet"]["publishedAt"].split("T")[0]
                    if published_at < start_date:
                        stop_collecting = True; break
                    videos.append({"id": video_id, "title": title, "date": published_at})
                next_page_token = pl_res.get("nextPageToken")
                if not next_page_token: break
            except: break
        return videos, channel_title
    except: return [], "Unknown"

# ==========================================
# 5~7. ì²˜ë¦¬ ë¡œì§ (ìë§‰, ìš”ì•½, ì›Œì»¤)
# ==========================================
def get_transcript_sync(video_id):
    if not PROXY_USERNAME or not PROXY_PASSWORD: raise ValueError("í”„ë¡ì‹œ ì •ë³´ ì—†ìŒ")
    proxy_config = WebshareProxyConfig(proxy_username=PROXY_USERNAME, proxy_password=PROXY_PASSWORD)
    ytt_api = YouTubeTranscriptApi(proxy_config=proxy_config)
    transcript_data = ytt_api.fetch(video_id, languages=['ko'])
    return " ".join(snippet.text for snippet in transcript_data.snippets)

async def summarize_text_task(text):
    if not text: return "ìë§‰ ì—†ìŒ"
    input_text = text[:GPT_INPUT_LIMIT]
    system_prompt = "ìœ íŠœë¸Œ ì˜ìƒì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ë‚´ìš© 5~10ê°€ì§€ë¥¼ í•œêµ­ì–´ ë¶ˆë › í¬ì¸íŠ¸ë¡œ(-)ìš”ì•½í•˜ì„¸ìš”."
    response = await aclient.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": input_text}]
    )
    return response.choices[0].message.content

async def process_video(video, channel_name, pbar, processed_in_channel, channels_task_counts):
    async with semaphore: 
        video_url = f"https://www.youtube.com/watch?v={video['id']}"
        await asyncio.sleep(random.uniform(0.5, 1.5)) 
        
        script = await retry_action(get_transcript_sync, video['id'], retries=3, delay=60, description=f"[{channel_name}] ìë§‰")
        summary = "ìš”ì•½ ë¶ˆê°€"
        saved_script = "ìë§‰ ì—†ìŒ"
        
        if script:
            summary_result = await retry_action(summarize_text_task, script, retries=3, delay=60, description=f"[{channel_name}] ìš”ì•½")
            if summary_result: summary = summary_result
            saved_script = script[:SHEET_CELL_LIMIT] + "...(ì ˆì‚­)" if len(script) > SHEET_CELL_LIMIT else script
        
        pbar.update(1)
        processed_in_channel[channel_name] = processed_in_channel.get(channel_name, 0) + 1
        
        # ì„ì—¬ì„œ ì™„ë£Œë˜ë¯€ë¡œ ì™„ë£Œ ë©”ì‹œì§€ê°€ ì‚°ë°œì ìœ¼ë¡œ ëœ° ìˆ˜ ìˆìŒ
        if processed_in_channel[channel_name] == channels_task_counts[channel_name]:
            pbar.write(f"âœ… {channel_name} ì™„ë£Œ ({channels_task_counts[channel_name]}ê°œ)")
    
        return [channel_name, video['date'], video['title'], saved_script, summary, video_url]

# # ==========================================
# # [NEW] 9. ì‹¤íŒ¨ í•­ëª© ì¬ì‹œë„ (A/S) ê¸°ëŠ¥
# # ==========================================
# async def repair_failed_rows(sheet):
#     print("\nğŸ”§ [A/S ë‹¨ê³„] 'ìš”ì•½ ë¶ˆê°€' í•­ëª© ì¬ì‘ì—… ì‹œì‘...")
    
#     # 1. ì‹œíŠ¸ ë°ì´í„° ì „ì²´ ì½ê¸°
#     try:
#         # get_all_valuesëŠ” ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ retry_actionìœ¼ë¡œ ë³´í˜¸í•˜ì§€ ì•Šì•„ë„ ë˜ì§€ë§Œ, 
#         # API ì˜¤ë¥˜ ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë¯€ë¡œ ê°„ë‹¨í•œ try-except ì²˜ë¦¬
#         rows = sheet.get_all_values()
#     except Exception as e:
#         print(f"âŒ ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
#         return

#     # 2. ì‹¤íŒ¨í•œ í–‰ ì¶”ì¶œ (í—¤ë” ì œì™¸)
#     failed_tasks = []
#     # rows[i]ëŠ” ì—‘ì…€ì˜ i+1í–‰ (0ë²ˆì€ í—¤ë”)
#     for i, row in enumerate(rows):
#         if i == 0: continue 
        
#         # ì•ˆì „ì¥ì¹˜: í–‰ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ê±´ë„ˆëœ€
#         if len(row) < 6: continue
        
#         # row ì¸ë±ìŠ¤: 0:ì±„ë„, 1:ë‚ ì§œ, 2:ì œëª©, 3:ìŠ¤í¬ë¦½íŠ¸, 4:ìš”ì•½, 5:URL
#         script = row[3]
#         summary = row[4]
#         url = row[5]
        
#         # ì¡°ê±´: 'ìš”ì•½ ë¶ˆê°€'ì´ê±°ë‚˜ ë¹„ì–´ìˆëŠ”ë°, URLì€ ì •ìƒì ì¸ ê²½ìš°
#         if (summary.strip() == "ìš”ì•½ ë¶ˆê°€" or summary.strip() == "") and url.strip().startswith("http"):
#             failed_tasks.append({
#                 "row_idx": i + 1, # ì—‘ì…€ í–‰ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
#                 "channel": row[0],
#                 "script": script,
#                 "url": url
#             })
            
#     if not failed_tasks:
#         print("âœ¨ ëª¨ë“  í•­ëª©ì´ ì •ìƒì…ë‹ˆë‹¤. ì¬ì‘ì—…í•  ê²ƒì´ ì—†ìŠµë‹ˆë‹¤.")
#         return

#     print(f"âš ï¸ ì´ {len(failed_tasks)}ê°œì˜ ì‹¤íŒ¨ í•­ëª© ë°œê²¬! ì‹¬íì†Œìƒìˆ  ì‹œë„í•©ë‹ˆë‹¤...")

#     # 3. ì¬ì‘ì—… ì›Œì»¤ ì •ì˜
#     async def repair_worker(task):
#         async with semaphore: # ë™ì‹œ ì‹¤í–‰ ì œí•œ
#             row_num = task['row_idx']
#             url = task['url']
#             channel_name = task['channel']
#             current_script = task['script']
            
#             # Video ID ì¶”ì¶œ
#             try:
#                 if "v=" in url:
#                     video_id = url.split("v=")[1].split("&")[0]
#                 else:
#                     return None
#             except:
#                 return None

#             # [ë‹¨ê³„ 1] ìë§‰ì´ ì—†ë‹¤ë©´ ìë§‰ë¶€í„° ë‹¤ì‹œ ì‹œë„
#             if not current_script or current_script == "ìë§‰ ì—†ìŒ":
#                 await asyncio.sleep(random.uniform(0.5, 1.5))
#                 # ì¬ì‹œë„ íšŸìˆ˜ 2íšŒ
#                 fetched_script = await retry_action(get_transcript_sync, video_id, retries=2, delay=30, description=f"[{channel_name}] ìë§‰ ì¬ìˆ˜ì§‘")
#                 if fetched_script:
#                     current_script = fetched_script
            
#             # [ë‹¨ê³„ 2] ìë§‰ì´ í™•ë³´ë˜ì—ˆë‹¤ë©´ ìš”ì•½ ì¬ì‹œë„
#             new_summary = "ìš”ì•½ ë¶ˆê°€"
#             final_script = current_script
            
#             if current_script and current_script != "ìë§‰ ì—†ìŒ":
#                 # ìš”ì•½ ì¬ì‹œë„ (ì¬ì‹œë„ íšŸìˆ˜ 2íšŒ)
#                 summary_res = await retry_action(summarize_text_task, current_script, retries=2, delay=30, description=f"[{channel_name}] ìš”ì•½ ì¬ì‹œë„")
#                 if summary_res:
#                     new_summary = summary_res
            
#             # [ë‹¨ê³„ 3] ê²°ê³¼ê°€ ê°œì„ ë˜ì—ˆìœ¼ë©´ ë¦¬í„´ ('ìš”ì•½ ë¶ˆê°€' íƒˆì¶œí–ˆê±°ë‚˜, ìë§‰ì´ë¼ë„ ê±´ì¡Œê±°ë‚˜)
#             if new_summary != "ìš”ì•½ ë¶ˆê°€" or (current_script != "ìë§‰ ì—†ìŒ" and task['script'] == "ìë§‰ ì—†ìŒ"):
#                 # ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ ì ˆì‚­
#                 if len(current_script) > SHEET_CELL_LIMIT:
#                     final_script = current_script[:SHEET_CELL_LIMIT] + "...(ì ˆì‚­)"
                
#                 return (row_num, final_script, new_summary, channel_name)
            
#             return None

#     # 4. ì¬ì‘ì—… ì‹¤í–‰
#     pbar = tqdm(total=len(failed_tasks), desc="ğŸ”§ A/S ì§„í–‰ ì¤‘")
#     tasks = [asyncio.create_task(repair_worker(t)) for t in failed_tasks]
    
#     success_count = 0
    
#     for future in asyncio.as_completed(tasks):
#         result = await future
#         pbar.update(1)
        
#         if result:
#             row_num, script_txt, summary_txt, ch_name = result
            
#             # êµ¬ê¸€ ì‹œíŠ¸ íŠ¹ì • ì…€ ì—…ë°ì´íŠ¸ (Dì—´=ìë§‰, Eì—´=ìš”ì•½)
#             # updateëŠ” API í˜¸ì¶œì´ë¯€ë¡œ retry ì ìš©
#             cell_range = f"D{row_num}:E{row_num}"
#             try:
#                 await retry_action(
#                     sheet.update, cell_range, [[script_txt, summary_txt]],
#                     retries=3, delay=60, description=f"{ch_name} í–‰ ì—…ë°ì´íŠ¸"
#                 )
#                 success_count += 1
#                 pbar.write(f"âœ… {ch_name} (í–‰ {row_num}) ë³µêµ¬ ì„±ê³µ!")
#             except Exception as e:
#                 pbar.write(f"âŒ í–‰ {row_num} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

#     pbar.close()
#     print(f"âœ¨ A/S ì™„ë£Œ: ì´ {success_count}ê°œ í•­ëª©ì„ ì‚´ë ¤ëƒˆìŠµë‹ˆë‹¤!")

# ==========================================
# 8. ë©”ì¸ ì‹¤í–‰ (ìˆ˜ì •ë¨)
# ==========================================
async def async_main():
    target_channel_ids = fetch_channel_ids_from_sheet()
    if not target_channel_ids: return
    
    sheet = connect_google_sheet(TARGET_SHEET_NAME)
    try: existing_urls = set(sheet.col_values(6))
    except: existing_urls = set()

    all_video_tasks_info = []
    channels_task_counts = {}
    channel_names_display = []

    print(f"\nğŸ“… ê¸°ì¤€ ë‚ ì§œ: {START_DATE}")
    print(f"ğŸ§ª ìˆ˜ì§‘ ëª¨ë“œ: ì±„ë„ë‹¹ {TEST_NUM if TEST_NUM else 'ì „ì²´'}")
    print("-" * 50)

    # 1. íƒœìŠ¤í¬ ëª©ë¡ ìƒì„±
    for ch_id in target_channel_ids:
        videos, channel_name = get_all_videos(ch_id, START_DATE)
        channel_names_display.append(channel_name)
        
        new_videos = []
        for v in videos:
            if f"https://www.youtube.com/watch?v={v['id']}" not in existing_urls:
                new_videos.append(v)
        
        if TEST_NUM and len(new_videos) > TEST_NUM:
            new_videos = new_videos[:TEST_NUM]
        
        all_video_tasks_info.extend([(v, channel_name) for v in new_videos])
        channels_task_counts[channel_name] = len(new_videos)
        
        if len(new_videos) > 0:
            print(f"   ğŸ‘‰ {channel_name}: {len(new_videos)}ê°œ")

    total_count = len(all_video_tasks_info)
    
    # [ìˆ˜ì •] ìˆ˜ì§‘í•  ê²Œ ì—†ì–´ë„, ë°”ë¡œ ì¢…ë£Œí•˜ì§€ ì•Šê³  'ì¬ì‘ì—…(A/S)' ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ê²Œ í•¨
    if total_count > 0:
        print("-" * 50)
        print(f"ğŸ”¢ ì´ {total_count}ê°œ ì˜ìƒ -> ë¬´ì‘ìœ„ ì„ì–´ì„œ ë™ì‹œ ì²˜ë¦¬ ì‹œì‘")
        print("-" * 50)

        random.shuffle(all_video_tasks_info)

        processed_in_channel = {}
        buffer = []
        
        with tqdm(total=total_count, desc="âš¡ ê³ ì† ì²˜ë¦¬ ì¤‘") as pbar:
            tasks = [
                asyncio.create_task(process_video(v, name, pbar, processed_in_channel, channels_task_counts)) 
                for v, name in all_video_tasks_info
            ]
            
            for future in asyncio.as_completed(tasks):
                result = await future 
                if result: buffer.append(result)
                
                if len(buffer) >= 50:
                    pbar.write(f"ğŸš€ ë²„í¼ ê°€ë“ ì°¸ (50ê°œ) -> êµ¬ê¸€ ì‹œíŠ¸ ì¦‰ì‹œ ì €ì¥")
                    upload_data = list(buffer)
                    buffer.clear() 
                    await retry_action(sheet.append_rows, upload_data, retries=5, delay=60, description="êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥")
                    
            if buffer:
                pbar.write(f"ğŸš€ ë‚˜ë¨¸ì§€ {len(buffer)}ê°œ -> êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥")
                await retry_action(sheet.append_rows, buffer, retries=5, delay=60, description="ë§ˆì§€ë§‰ ì €ì¥")
    else:
        print("ğŸ‰ ìƒˆë¡œ ìˆ˜ì§‘í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. ë°”ë¡œ A/S ë‹¨ê³„ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")

    # # ==========================================
    # # [ë§ˆì§€ë§‰ ë‹¨ê³„] ì‹¤íŒ¨í•œ í•­ëª© ì¬ì‹œë„ ì‹¤í–‰
    # # ==========================================
    # print("-" * 50)
    # await repair_failed_rows(sheet)
    # print("-" * 50)

    print("\nğŸ‰ ëª¨ë“  ì‘ì—…(ìˆ˜ì§‘+ë³µêµ¬)ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    asyncio.run(async_main())